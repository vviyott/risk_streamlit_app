# utils/function_calling_system.py

import os
import json
import sqlite3
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import tool
from functools import lru_cache
from utils.recall_prompts import RecallPrompts

load_dotenv()

# ì „ì—­ ë³€ìˆ˜ - ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤
_sqlite_conn = None
_vectorstore = None  
_logical_processor = None
_db_initialized = False

def initialize_sqlite_db(db_path="./data/fda_recalls.db"):
    """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™” (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    try:
        if not os.path.exists(db_path):
            print(f"âŒ SQLite ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_path}")
            return None
        
        # ğŸ”§ ìŠ¤ë ˆë“œ ì•ˆì „ ì„¤ì •
        conn = sqlite3.connect(
            db_path, 
            check_same_thread=False,  # ìŠ¤ë ˆë“œ ì•ˆì „ì„± í•´ì œ
            timeout=30.0  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        )
        conn.row_factory = sqlite3.Row
        
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) as count FROM recalls")
        total_records = cursor.fetchone()['count']
        print(f"âœ… SQLite ì—°ê²° ì„±ê³µ: {total_records}ê°œ ë ˆì½”ë“œ")
        
        return conn
        
    except Exception as e:
        print(f"âŒ SQLite ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def initialize_recall_vectorstore():
    """ChromaDB ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
    persist_dir = "./data/chroma_db_recall"
    
    if os.path.exists(persist_dir) and os.listdir(persist_dir):
        try:
            print("ê¸°ì¡´ ë¦¬ì½œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            
            vectorstore = Chroma(
                persist_directory=persist_dir,
                embedding_function=embeddings,
                collection_name="FDA_recalls"
            )
            
            collection = vectorstore._collection
            doc_count = collection.count()
            print(f"âœ… ë¦¬ì½œ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ ({doc_count}ê°œ ë¬¸ì„œ)")
            return vectorstore
                
        except Exception as e:
            print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return None
    
def parse_relative_dates(period_text: str) -> str:
    """ìƒëŒ€ì  ë‚ ì§œ í‘œí˜„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜ (2025ë…„ ê¸°ì¤€)"""
    import datetime
    
    current_year = datetime.datetime.now().year  # 2025
    
    # ğŸ”§ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ í‘œí˜„ ë§¤í•‘
    korean_mappings = {
        "ì˜¬í•´": str(current_year),           # 2025 âœ…
        "ì‘ë…„": str(current_year - 1),       # 2024 âœ…  
        "ì¬ì‘ë…„": str(current_year - 2),     # 2023 âœ…
        "ì´ë²ˆë…„": str(current_year),         # 2025
        "í˜„ì¬": str(current_year),           # 2025
        "ì§€ë‚œí•´": str(current_year - 1),     # 2024 âœ…
        "ì „ë…„": str(current_year - 1),       # 2024 âœ…
        "ê¸ˆë…„": str(current_year),           # 2025
        "ì‘ë…„ë„": str(current_year - 1),     # 2024
        "ì˜¬í•´ë…„ë„": str(current_year),       # 2025
    }
    
    period_lower = period_text.lower().strip()
    
    # í•œêµ­ì–´ ë§¤í•‘ í™•ì¸
    for korean, year in korean_mappings.items():
        if korean in period_lower:
            print(f"ğŸ”§ ë‚ ì§œ ë§¤í•‘: '{period_text}' â†’ {year}ë…„ (í˜„ì¬: {current_year})")
            return year
    
    # ìˆ«ìì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if period_text.isdigit() and len(period_text) == 4:
        return period_text
    
    # ì¸ì‹í•˜ì§€ ëª»í•œ ê²½ìš° í˜„ì¬ ì—°ë„ ë°˜í™˜
    print(f"âš ï¸ ë‚ ì§œ ì¸ì‹ ì‹¤íŒ¨: '{period_text}' â†’ ê¸°ë³¸ê°’ {current_year}ë…„ ì‚¬ìš©")
    return str(current_year)

@lru_cache(maxsize=512) # ë™ì¼ í‚¤ì›Œë“œê°€ ë°˜ë³µ í˜¸ì¶œë  ë•Œ ì†ë„/ë¹„ìš© ì¤„ì¼ ìˆ˜ ìˆìŒ
def translate_to_english(korean_text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜"""
    from langchain_openai import ChatOpenAI
    
    try:
        translator = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0
        )
        
        translation_prompt = f"""
ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ì •í™•íˆ ë²ˆì—­í•´ì£¼ì„¸ìš”. 
ì‹í’ˆ, ë¦¬ì½œ, ì•Œë ˆë¥´ê² ê´€ë ¨ ì „ë¬¸ ìš©ì–´ëŠ” FDA í‘œì¤€ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

í•œêµ­ì–´: {korean_text}
ì˜ì–´:"""
        
        response = translator.invoke([{"role": "user", "content": translation_prompt}])
        english_text = response.content.strip()
        
        print(f"ğŸ”„ ë²ˆì—­: '{korean_text}' â†’ '{english_text}'")
        return english_text
        
    except Exception as e:
        print(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤í•‘ ì‚¬ìš©
        return korean_text

# ìƒì„¸ ì˜¤ì—¼ì›/ë³‘ì›ì²´ ê°ì§€ìš© í—¬í¼ ì¶”ê°€
_DETAIL_TERMS = {
    "salmonella", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "listeria", "listeria monocytogenes",
    "e. coli", "ecoli", "escherichia", "norovirus", "ë…¸ë¡œë°”ì´ëŸ¬ìŠ¤",
    "campylobacter", "shigella", "clostridium", "botulinum"
}

def _looks_like_detail(value: Optional[str]) -> bool:
    if not value:
        return False
    v = value.lower()
    v_en = translate_to_english(value).lower()
    return any(k in v or k in v_en for k in _DETAIL_TERMS)

def get_recall_vectorstore():
    """tab_recall.py í˜¸í™˜ìš© í•¨ìˆ˜"""
    return initialize_recall_vectorstore()

def _get_system_components():
    global _sqlite_conn, _vectorstore, _db_initialized
    
    if not _db_initialized:
        _sqlite_conn = initialize_sqlite_db()
        _vectorstore = initialize_recall_vectorstore()
        _db_initialized = True
    
    return _sqlite_conn, _vectorstore, None  

# ìŠ¤ë§ˆíŠ¸ í•„ë“œ ë§¤í•‘ í•¨ìˆ˜ (ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ìë™ í•„ë“œ ì„ íƒ)
def smart_count_recalls(query: str, **filters) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ì„í•´ì„œ ì ì ˆí•œ í•„ë“œë¡œ ìë™ ë§¤í•‘í•˜ëŠ” ë˜í¼ í•¨ìˆ˜
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "ê³„ë€ ê´€ë ¨ ë¦¬ì½œ ì´ ëª‡ ê±´?" â†’ keyword="ê³„ë€" (ëª¨ë“  í•„ë“œ ê²€ìƒ‰)
    - "2024ë…„ ì‚´ëª¨ë„¬ë¼ ê±´ìˆ˜ëŠ”?" â†’ year="2024", recall_detail="ì‚´ëª¨ë„¬ë¼"
    - "ëª¬ë¸ë¦¬ì¦ˆ íšŒì‚¬ ë¦¬ì½œ ëª‡ ê±´?" â†’ company="ëª¬ë¸ë¦¬ì¦ˆ"
    """
    
    query_lower = query.lower()
    
    # ğŸ¯ í‚¤ì›Œë“œ íŒ¨í„´ ë¶„ì„
    specific_contaminants = {
        "ì‚´ëª¨ë„¬ë¼": "salmonella",
        "ë¦¬ìŠ¤í…Œë¦¬ì•„": "listeria", 
        "ëŒ€ì¥ê· ": "e.coli",
        "í´ë¡œìŠ¤íŠ¸ë¦¬ë“": "clostridium"
    }
    
    allergen_keywords = {
        "ìš°ìœ ": "milk",
        "ê³„ë€": "egg", 
        "ê²¬ê³¼ë¥˜": "tree nuts",
        "ë•…ì½©": "peanut",
        "ì½©": "soy",
        "ë°€": "wheat"
    }
    
    product_categories = {
        "ê³¼ì": "snacks",
        "ìœ ì œí’ˆ": "dairy",
        "í•´ì‚°ë¬¼": "seafood", 
        "ìœ¡ë¥˜": "meat",
        "ì±„ì†Œ": "vegetables"
    }
    
    # ìë™ í•„ë“œ ë§¤í•‘
    auto_filters = filters.copy()
    
    # 1. êµ¬ì²´ì ì¸ ì˜¤ì—¼ë¬¼ì§ˆ ê°ì§€
    for ko_term, en_term in specific_contaminants.items():
        if ko_term in query or en_term in query_lower:
            auto_filters["recall_reason_detail"] = ko_term
            break
    
    # 2. ì•Œë ˆë¥´ê² ê°ì§€ (ì•Œë ˆë¥´ê² ê´€ë ¨ ì§ˆë¬¸)
    for ko_term, en_term in allergen_keywords.items():
        if ko_term in query or en_term in query_lower:
            if "ì•Œë ˆë¥´ê²" in query or "allergen" in query_lower:
                auto_filters["recall_reason_detail"] = f"{ko_term} ì•Œë ˆë¥´ê²"
            else:
                auto_filters["keyword"] = ko_term  # í†µí•© ê²€ìƒ‰
            break
    
    # 3. ì œí’ˆ ì¹´í…Œê³ ë¦¬ ê°ì§€
    for ko_term, en_term in product_categories.items():
        if ko_term in query or en_term in query_lower:
            auto_filters["product_type"] = ko_term
            break
    
    # 4. ì—°ë„ ì¶”ì¶œ
    import re
    year_match = re.search(r'(20\d{2})', query)
    if year_match and not auto_filters.get("year"):
        auto_filters["year"] = year_match.group(1)
    
    print(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ë§¤í•‘: '{query}' â†’ {auto_filters}")
    
    return count_recalls(**auto_filters)

# ìŠ¤ë§ˆíŠ¸ ìˆœìœ„ ë¶„ì„ í•¨ìˆ˜ (smart_count_recalls ìŠ¤íƒ€ì¼)
def smart_rank_by_field(query: str, limit: int = 10, **filters) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì ì ˆí•œ í•„ë“œë¡œ ìë™ ìˆœìœ„ ë¶„ì„
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "ë³µí•© ê°€ê³µì‹í’ˆ ì£¼ìš” ë¦¬ì½œ ì‚¬ìœ  4ê°€ì§€" â†’ field="recall_reason", product_type="ë³µí•© ê°€ê³µì‹í’ˆ", limit=4
    - "2024ë…„ ìƒìœ„ íšŒì‚¬ 5ê³³" â†’ field="company", year="2024", limit=5  
    - "ì•Œë ˆë¥´ê² ê´€ë ¨ ì£¼ìš” ë¸Œëœë“œ" â†’ field="brand", keyword="ì•Œë ˆë¥´ê²"
    """
    
    query_lower = query.lower()
    
    # ğŸ¯ í•„ë“œ íƒ€ì… ìë™ ê°ì§€
    field_patterns = {
        "íšŒì‚¬": "company",
        "company": "company", 
        "ê¸°ì—…": "company",
        
        "ë¸Œëœë“œ": "brand",
        "brand": "brand",
        "ìƒí‘œ": "brand",
        
        "ì œí’ˆ": "product_type",
        "product": "product_type",
        "ì‹í’ˆ": "product_type",
        
        "ì‚¬ìœ ": "recall_reason", 
        "ì›ì¸": "recall_reason",
        "reason": "recall_reason",
        
        "ì˜¤ì—¼ë¬¼ì§ˆ": "recall_detail",
        "ì„¸ê· ": "recall_detail",
        "ì•Œë ˆë¥´ê²": "recall_detail",
        "contaminant": "recall_detail"
    }
    
    # ìë™ í•„ë“œ ê°ì§€
    detected_field = "recall_reason"  # ê¸°ë³¸ê°’
    for pattern, field_type in field_patterns.items():
        if pattern in query_lower:
            detected_field = field_type
            break
    
    # ìˆ«ì íŒ¨í„´ì—ì„œ limit ì¶”ì¶œ
    import re
    number_matches = re.findall(r'(\d+)', query)
    if number_matches:
        detected_limit = min(int(number_matches[0]), 20)  # ìµœëŒ€ 20ê°œ
        if detected_limit > 0:
            limit = detected_limit
    
    # ì œí’ˆ ì¹´í…Œê³ ë¦¬ ê°ì§€
    product_categories = {
        "ë³µí•©": "processed",
        "ê°€ê³µì‹í’ˆ": "processed foods", 
        "processed": "processed foods",
        "ê³¼ì": "snacks",
        "ìœ ì œí’ˆ": "dairy", 
        "í•´ì‚°ë¬¼": "seafood",
        "ìœ¡ë¥˜": "meat"
    }
    
    auto_filters = filters.copy()
    for ko_term, en_term in product_categories.items():
        if ko_term in query:
            auto_filters["product_type"] = ko_term
            break
    
    # ì—°ë„ ì¶”ì¶œ
    year_match = re.search(r'(20\d{2})', query)
    if year_match and not auto_filters.get("year"):
        auto_filters["year"] = year_match.group(1)
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ (ì•Œë ˆë¥´ê², ì˜¤ì—¼ë¬¼ì§ˆ ë“±)
    keyword_patterns = ["ì•Œë ˆë¥´ê²", "allergen", "ì„¸ê· ", "bacterial", "ì˜¤ì—¼", "contamination"]
    for pattern in keyword_patterns:
        if pattern in query_lower and not auto_filters.get("keyword"):
            auto_filters["keyword"] = pattern
            break
    
    print(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ìˆœìœ„ ë¶„ì„: '{query}' â†’ field='{detected_field}', limit={limit}, filters={auto_filters}")
    
    return rank_by_field(field=detected_field, limit=limit, **auto_filters)

def calculate_filter_statistics(cursor, include_terms: Optional[List[str]], exclude_terms: List[str]) -> Dict[str, int]:
    """í•„í„°ë§ í†µê³„ ê³„ì‚°"""
    
    try:
        # ì „ì²´ ë°ì´í„° ìˆ˜
        cursor.execute("SELECT COUNT(*) as total FROM recalls")
        total_count = cursor.fetchone()["total"]
        
        # í¬í•¨ ì¡°ê±´ ë§¤ì¹­ ìˆ˜ (include_termsê°€ ìˆëŠ” ê²½ìš°)
        include_count = total_count
        if include_terms:
            include_sql = "SELECT COUNT(*) as count FROM recalls WHERE 1=1"
            include_params = []
            
            include_conditions = []
            for term in include_terms:
                english_term = translate_to_english(term)
                search_terms = [term, english_term] if english_term != term else [term]
                
                for search_term in search_terms:
                    include_conditions.append("""(
                        LOWER(company_name) LIKE LOWER(?) OR
                        LOWER(brand_name) LIKE LOWER(?) OR
                        LOWER(product_type) LIKE LOWER(?) OR
                        LOWER(recall_reason) LIKE LOWER(?) OR
                        LOWER(recall_reason_detail) LIKE LOWER(?) OR
                        LOWER(content) LIKE LOWER(?)
                    )""")
                    include_params.extend([f"%{search_term}%"] * 6)
            
            include_sql += f" AND ({' OR '.join(include_conditions)})"
            cursor.execute(include_sql, include_params)
            include_count = cursor.fetchone()["count"]
        
        # ì œì™¸ ì¡°ê±´ ë§¤ì¹­ ìˆ˜
        exclude_count = 0
        if exclude_terms:
            exclude_sql = "SELECT COUNT(*) as count FROM recalls WHERE 1=1"
            exclude_params = []
            
            exclude_conditions = []
            for term in exclude_terms:
                english_term = translate_to_english(term)
                search_terms = [term, english_term] if english_term != term else [term]
                
                term_conditions = []
                for search_term in search_terms:
                    term_conditions.append("""(
                        LOWER(company_name) LIKE LOWER(?) OR
                        LOWER(brand_name) LIKE LOWER(?) OR
                        LOWER(product_type) LIKE LOWER(?) OR
                        LOWER(recall_reason) LIKE LOWER(?) OR
                        LOWER(recall_reason_detail) LIKE LOWER(?) OR
                        LOWER(content) LIKE LOWER(?)
                    )""")
                    exclude_params.extend([f"%{search_term}%"] * 6)
                
                exclude_conditions.append(f"({' OR '.join(term_conditions)})")
            
            exclude_sql += f" AND ({' OR '.join(exclude_conditions)})"
            cursor.execute(exclude_sql, exclude_params)
            exclude_count = cursor.fetchone()["count"]
        
        # ìµœì¢… í•„í„°ë§ ê²°ê³¼ ìˆ˜ ê³„ì‚°
        final_count = include_count - exclude_count if exclude_count > 0 else include_count
        
        return {
            "total_records": total_count,
            "include_matches": include_count,
            "exclude_matches": exclude_count, 
            "final_filtered": max(0, final_count),
            "exclusion_rate": round((exclude_count / include_count * 100), 1) if include_count > 0 else 0
        }
        
    except Exception as e:
        return {
            "total_records": 0,
            "include_matches": 0,
            "exclude_matches": 0,
            "final_filtered": 0,
            "error": str(e)
        }

# ======================
# Function Calling ë„êµ¬ë“¤
# ======================

REASON_CATEGORIES = {
    "allergens", "illness", "labeling", "contaminants",
    "microbiological", "foreign material", "quality",
    "packaging", "undetermined", "other"
}

@tool
def count_recalls(
    company: Optional[str] = None,
    product_type: Optional[str] = None,
    brand: Optional[str] = None,
    recall_reason: Optional[str] = None,            # ë¦¬ì½œ ëŒ€ë¶„ë¥˜(ì¹´í…Œê³ ë¦¬)
    recall_reason_detail: Optional[str] = None,     # ë¦¬ì½œ ì„¸ë¶€ ì›ì¸(ì‚´ëª¨ë„¬ë¼ ë“±)
    year: Optional[str] = None,
    keyword: Optional[str] = None) -> Dict[str, Any]:
    """ë¦¬ì½œ ê±´ìˆ˜ë¥¼ ì„¸ëŠ” í•¨ìˆ˜ (SQLite ê¸°ë°˜) - í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤"""

    sqlite_conn, _, _ = _get_system_components()
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}

    try:
        # LLMì´ ì‹¤ìˆ˜ë¡œ recall_reason="Salmonella"ì²˜ëŸ¼ ë„˜ê²¨ë„ ìë™ ë³´ì •
        if recall_reason and not recall_reason_detail and _looks_like_detail(recall_reason):
            recall_reason_detail = recall_reason
            recall_reason = None

        sql = "SELECT COUNT(*) as count FROM recalls WHERE 1=1"
        params = []

        # í†µí•© í‚¤ì›Œë“œ ê²€ìƒ‰ (ëª¨ë“  ì£¼ìš” í•„ë“œì—ì„œ ê²€ìƒ‰)
        if keyword:
            english_keyword = translate_to_english(keyword)
            search_terms = [keyword, english_keyword] if english_keyword != keyword else [keyword]
            
            print(f"ğŸ” í†µí•© ê²€ìƒ‰ì–´: {search_terms}")
            
            search_conditions = []
            for term in search_terms:
                search_conditions.append("""(
                    LOWER(company_name) LIKE LOWER(?) OR 
                    LOWER(brand_name) LIKE LOWER(?) OR
                    LOWER(product_type) LIKE LOWER(?) OR
                    LOWER(recall_reason) LIKE LOWER(?) OR
                    LOWER(recall_reason_detail) LIKE LOWER(?) OR
                    LOWER(content) LIKE LOWER(?)
                )""")
                params.extend([f"%{term}%"] * 6)
            sql += f" AND ({' OR '.join(search_conditions)})"
				
				# ê°œë³„ í•„í„°ë“¤ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤)
        if company:
            english_company = translate_to_english(company)
            company_terms = [company, english_company] if english_company != company else [company]
            company_conditions = []
            for term in company_terms:
                company_conditions.append("LOWER(company_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(company_conditions)})"

        if brand:
            english_brand = translate_to_english(brand)
            brand_terms = [brand, english_brand] if english_brand != brand else [brand]
            brand_conditions = []
            for term in brand_terms:
                brand_conditions.append("LOWER(brand_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(brand_conditions)})"

        if product_type:
            english_product_type = translate_to_english(product_type)
            product_type_terms = [product_type, english_product_type] if english_product_type != product_type else [product_type]
            product_type_conditions = []
            for term in product_type_terms:
                product_type_conditions.append("LOWER(product_type) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(product_type_conditions)})"

        # ëŒ€ë¶„ë¥˜
        if recall_reason:
            english_recall_reason = translate_to_english(recall_reason)
            recall_reason_terms = [recall_reason, english_recall_reason] if english_recall_reason != recall_reason else [recall_reason]
            recall_reason_conditions = []
            for term in recall_reason_terms:
                recall_reason_conditions.append("LOWER(recall_reason) = LOWER(?)")
                params.append(term)
            sql += f" AND ({' OR '.join(recall_reason_conditions)})"

        # ìƒì„¸ ë¦¬ì½œ ì‚¬ìœ  ê²€ìƒ‰ (ì‚´ëª¨ë„¬ë¼, ë¦¬ìŠ¤í…Œë¦¬ì•„ ë“± êµ¬ì²´ì  ì˜¤ì—¼ë¬¼ì§ˆ)
        if recall_reason_detail:
            english_recall_detail = translate_to_english(recall_reason_detail)
            recall_detail_terms = [recall_reason_detail, english_recall_detail] if english_recall_detail != recall_reason_detail else [recall_reason_detail]
            recall_detail_conditions = []
            for term in recall_detail_terms:
                recall_detail_conditions.append("LOWER(recall_reason_detail) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(recall_detail_conditions)})"

				# ë‚ ì§œ í•„í„° (fda_publish_date ì‚¬ìš©)
        if year:
            if len(year) == 4: # ì—°ë„ë§Œ
                sql += " AND strftime('%Y', fda_publish_date) = ?"
                params.append(year)
            elif len(year) == 7: # YYYY-MM í˜•íƒœ
                sql += " AND strftime('%Y-%m', fda_publish_date) = ?"
                params.append(year)

        print(f"ğŸ”§ SQL ì¿¼ë¦¬: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")

        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        result = cursor.fetchone()

        return {
            "count": result["count"],
            "filters": {
                "company": company,
                "brand": brand,
                "product_type": product_type,
                "recall_reason": recall_reason,
                "recall_reason_detail": recall_reason_detail,
                "year": year,
                "keyword": keyword
            },
            "search_fields": "multiple" if keyword else "specific",
            "query_type": "unified_count",
            "database_fields_used": [
                "company_name", "brand_name", "product_type",
                "recall_reason", "recall_reason_detail", "fda_publish_date", "content"
            ]
        }

    except Exception as e:
        return {"error": f"SQL ì¹´ìš´íŒ… ì˜¤ë¥˜: {e}"}

@tool
def rank_by_field(field: str, limit: int = 10, 
                 company: Optional[str] = None,
                 product_type: Optional[str] = None,  # food_type â†’ product_type
                 brand: Optional[str] = None,         # ë¸Œëœë“œ í•„í„°
                 year: Optional[str] = None,
                 keyword: Optional[str] = None) -> Dict[str, Any]:  # í‚¤ì›Œë“œ í•„í„°
    """í•„ë“œë³„ ìˆœìœ„ ë¶„ì„ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤ + ìŠ¤ë§ˆíŠ¸ ë§¤í•‘)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        cursor = sqlite_conn.cursor()
        
        # í˜„ì¬ JSON êµ¬ì¡°ì— ë§ëŠ” í•„ë“œ ë§¤í•‘
        field_mapping = {
            "company": "company_name",
            "brand": "brand_name", 
            "product_type": "product_type",
            "product": "product_type",  # ë³„ì¹­
            "recall_reason": "recall_reason",
            "reason": "recall_reason",  # ë³„ì¹­
            "recall_detail": "recall_reason_detail",
            "detail": "recall_reason_detail",  # ë³„ì¹­
            "contaminant": "recall_reason_detail",  # ì˜¤ì—¼ë¬¼ì§ˆì€ ìƒì„¸ì‚¬ìœ ì—ì„œ
            "allergen": "recall_reason_detail"  # ì•Œë ˆë¥´ê²ë„ ìƒì„¸ì‚¬ìœ ì—ì„œ
        }
        
        # í•„ë“œ ì •ê·œí™”
        normalized_field = field.lower().replace("_", "").replace(" ", "")
        db_field = None
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        if field.lower() in field_mapping:
            db_field = field_mapping[field.lower()]
        # ë¶€ë¶„ ë§¤ì¹­
        else:
            for key, value in field_mapping.items():
                if key in normalized_field or normalized_field in key:
                    db_field = value
                    break
        
        # ê¸°ë³¸ê°’
        if not db_field:
            db_field = "recall_reason"  # ê¸°ë³¸ì ìœ¼ë¡œ ë¦¬ì½œ ì‚¬ìœ 
        
        print(f"ğŸ”§ í•„ë“œ ë§¤í•‘: '{field}' â†’ '{db_field}'")
        
        # SQL ì¿¼ë¦¬ êµ¬ì„±
        sql = f"""
            SELECT {db_field} as name, COUNT(*) as count 
            FROM recalls 
            WHERE {db_field} IS NOT NULL 
            AND {db_field} != '' 
            AND {db_field} != 'N/A'
        """
        params = []
        
        # í‚¤ì›Œë“œ í•„í„° (ì—¬ëŸ¬ í•„ë“œì—ì„œ í†µí•© ê²€ìƒ‰)
        if keyword:
            english_keyword = translate_to_english(keyword)
            search_terms = [keyword, english_keyword] if english_keyword != keyword else [keyword]
            
            keyword_conditions = []
            for term in search_terms:
                keyword_conditions.append("""(
                    LOWER(company_name) LIKE LOWER(?) OR 
                    LOWER(brand_name) LIKE LOWER(?) OR
                    LOWER(product_type) LIKE LOWER(?) OR
                    LOWER(recall_reason) LIKE LOWER(?) OR
                    LOWER(recall_reason_detail) LIKE LOWER(?)
                )""")
                params.extend([f"%{term}%"] * 5)
            
            sql += f" AND ({' OR '.join(keyword_conditions)})"
        
        # ê°œë³„ í•„í„°ë“¤
        if company and db_field != "company_name":
            english_company = translate_to_english(company)
            company_terms = [company, english_company] if english_company != company else [company]
            company_conditions = []
            for term in company_terms:
                company_conditions.append("LOWER(company_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(company_conditions)})"
            
        if brand and db_field != "brand_name":
            english_brand = translate_to_english(brand)
            brand_terms = [brand, english_brand] if english_brand != brand else [brand]
            brand_conditions = []
            for term in brand_terms:
                brand_conditions.append("LOWER(brand_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(brand_conditions)})"
            
        if product_type and db_field != "product_type":
            english_product_type = translate_to_english(product_type)
            product_type_terms = [product_type, english_product_type] if english_product_type != product_type else [product_type]
            product_type_conditions = []
            for term in product_type_terms:
                product_type_conditions.append("LOWER(product_type) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(product_type_conditions)})"
            
        if year:
            if len(year) == 4:  # ì—°ë„ë§Œ
                sql += " AND strftime('%Y', fda_publish_date) = ?"
                params.append(year)
            elif len(year) == 7:  # YYYY-MM í˜•íƒœ
                sql += " AND strftime('%Y-%m', fda_publish_date) = ?"
                params.append(year)

        sql += f" GROUP BY {db_field} ORDER BY count DESC LIMIT ?"
        params.append(limit)
        
        print(f"ğŸ”§ ìˆœìœ„ ë¶„ì„ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor.execute(sql, params)
        results = [{"name": row["name"], "count": row["count"]} for row in cursor.fetchall()]
        
        return {
            "ranking": results,
            "field": field,
            "db_field": db_field,  # ì‹¤ì œ ì‚¬ìš©ëœ DB í•„ë“œ
            "total_items": len(results),
            "filters": {
                "company": company,
                "brand": brand,
                "product_type": product_type, 
                "year": year,
                "keyword": keyword
            },
            "query_type": "field_ranking"
        }
        
    except Exception as e:
        return {"error": f"ìˆœìœ„ ë¶„ì„ ì˜¤ë¥˜: {e}"}
    
    
@tool 
def get_monthly_trend(months: int = 12,
                     product_type: Optional[str] = None,  # food_type â†’ product_type
                     company: Optional[str] = None,
                     brand: Optional[str] = None,         # ë¸Œëœë“œ í•„í„° ì¶”ê°€
                     recall_reason: Optional[str] = None, # ë¦¬ì½œ ì‚¬ìœ  í•„í„° ì¶”ê°€
                     keyword: Optional[str] = None,       # í‚¤ì›Œë“œ í•„í„° ì¶”ê°€
                     date_field: str = "fda") -> Dict[str, Any]:  # ë‚ ì§œ í•„ë“œ ì„ íƒ
    """ì›”ë³„ ë¦¬ì½œ íŠ¸ë Œë“œ ë¶„ì„ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤ + ë‹¤ì–‘í•œ í•„í„° ì§€ì›)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # ë‚ ì§œ í•„ë“œ ì„ íƒ (FDA ë°œí‘œì¼ vs íšŒì‚¬ ë°œí‘œì¼)
        if date_field.lower() in ["fda", "fda_publish"]:
            date_column = "fda_publish_date"
        elif date_field.lower() in ["company", "company_announcement"]:
            date_column = "company_announcement_date"
        else:
            date_column = "fda_publish_date"  # ê¸°ë³¸ê°’
        
        sql = f"""
            SELECT strftime('%Y-%m', {date_column}) as month, COUNT(*) as count
            FROM recalls 
            WHERE {date_column} IS NOT NULL
        """
        params = []
        
        # í‚¤ì›Œë“œ í†µí•© ê²€ìƒ‰
        if keyword:
            english_keyword = translate_to_english(keyword)
            search_terms = [keyword, english_keyword] if english_keyword != keyword else [keyword]
            
            keyword_conditions = []
            for term in search_terms:
                keyword_conditions.append("""(
                    LOWER(company_name) LIKE LOWER(?) OR 
                    LOWER(brand_name) LIKE LOWER(?) OR
                    LOWER(product_type) LIKE LOWER(?) OR
                    LOWER(recall_reason) LIKE LOWER(?) OR
                    LOWER(recall_reason_detail) LIKE LOWER(?)
                )""")
                params.extend([f"%{term}%"] * 5)
            
            sql += f" AND ({' OR '.join(keyword_conditions)})"
        
        # ê°œë³„ í•„í„°ë“¤ (í˜„ì¬ JSON êµ¬ì¡°)
        if product_type:
            english_product_type = translate_to_english(product_type)
            product_type_terms = [product_type, english_product_type] if english_product_type != product_type else [product_type]
            product_type_conditions = []
            for term in product_type_terms:
                product_type_conditions.append("LOWER(product_type) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(product_type_conditions)})"
            
        if company:
            english_company = translate_to_english(company)
            company_terms = [company, english_company] if english_company != company else [company]
            company_conditions = []
            for term in company_terms:
                company_conditions.append("LOWER(company_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(company_conditions)})"
            
        if brand:
            english_brand = translate_to_english(brand)
            brand_terms = [brand, english_brand] if english_brand != brand else [brand]
            brand_conditions = []
            for term in brand_terms:
                brand_conditions.append("LOWER(brand_name) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(brand_conditions)})"
            
        if recall_reason:
            english_recall_reason = translate_to_english(recall_reason)
            recall_reason_terms = [recall_reason, english_recall_reason] if english_recall_reason != recall_reason else [recall_reason]
            recall_reason_conditions = []
            for term in recall_reason_terms:
                recall_reason_conditions.append("LOWER(recall_reason) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(recall_reason_conditions)})"
        
        sql += " GROUP BY month ORDER BY month DESC LIMIT ?"
        params.append(months)
        
        print(f"ğŸ”§ íŠ¸ë Œë“œ ë¶„ì„ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        results = [{"month": row["month"], "count": row["count"]} for row in cursor.fetchall()]
        
        return {
            "trend": results,
            "months": months,
            "date_field": date_column,
            "filters": {
                "product_type": product_type,
                "company": company,
                "brand": brand,
                "recall_reason": recall_reason,
                "keyword": keyword
            },
            "query_type": "monthly_trend"
        }
        
    except Exception as e:
        return {"error": f"íŠ¸ë Œë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}"}
    

@tool
def compare_periods(period1: str, period2: str, 
                   metric: str = "count",
                   include_reasons: bool = False,       # ì‚¬ìœ ë³„ ë¶„ì„ í¬í•¨
                   product_type: Optional[str] = None,  # ì œí’ˆ ìœ í˜• í•„í„°
                   company: Optional[str] = None,       # íšŒì‚¬ í•„í„°
                   brand: Optional[str] = None,         # ë¸Œëœë“œ í•„í„°
                   keyword: Optional[str] = None,       # í‚¤ì›Œë“œ í•„í„°
                   date_field: str = "fda") -> Dict[str, Any]:  # ë‚ ì§œ í•„ë“œ ì„ íƒ
    """ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„ í•¨ìˆ˜ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤ + ë‹¤ì–‘í•œ í•„í„° ì§€ì›)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # ìƒëŒ€ì  ë‚ ì§œ í‘œí˜„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜
        actual_period1 = parse_relative_dates(period1)
        actual_period2 = parse_relative_dates(period2)
        
        print(f"ğŸ”§ ë‚ ì§œ ë³€í™˜: '{period1}' â†’ {actual_period1}, '{period2}' â†’ {actual_period2}")
        
        # ë‚ ì§œ í•„ë“œ ì„ íƒ
        if date_field.lower() in ["fda", "fda_publish"]:
            date_column = "fda_publish_date"
        elif date_field.lower() in ["company", "company_announcement"]:
            date_column = "company_announcement_date"
        else:
            date_column = "fda_publish_date"  # ê¸°ë³¸ê°’
        
        cursor = sqlite_conn.cursor()
        
        def get_period_data(period: str):
            """íŠ¹ì • ê¸°ê°„ì˜ ë°ì´í„° ì¡°íšŒ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤)"""
            
            # ë‚ ì§œ í•„í„° ì„¤ì •
            if len(period) == 4:  # ì—°ë„ (YYYY)
                date_filter = f"strftime('%Y', {date_column}) = ?"
            elif len(period) == 7:  # ì—°ì›” (YYYY-MM)
                date_filter = f"strftime('%Y-%m', {date_column}) = ?"
            else:
                return None
            
            result_data = {}
            
            # ê¸°ë³¸ WHERE ì ˆ êµ¬ì„±
            base_where = f"WHERE {date_filter}"
            base_params = [period]
            
            # ì¶”ê°€ í•„í„°ë“¤ ì ìš©
            additional_conditions = []
            additional_params = []
            
            # í‚¤ì›Œë“œ í†µí•© ê²€ìƒ‰
            if keyword:
                english_keyword = translate_to_english(keyword)
                search_terms = [keyword, english_keyword] if english_keyword != keyword else [keyword]
                
                keyword_conditions = []
                for term in search_terms:
                    keyword_conditions.append("""(
                        LOWER(company_name) LIKE LOWER(?) OR 
                        LOWER(brand_name) LIKE LOWER(?) OR
                        LOWER(product_type) LIKE LOWER(?) OR
                        LOWER(recall_reason) LIKE LOWER(?) OR
                        LOWER(recall_reason_detail) LIKE LOWER(?)
                    )""")
                    additional_params.extend([f"%{term}%"] * 5)
                
                additional_conditions.append(f"({' OR '.join(keyword_conditions)})")
            
            # ê°œë³„ í•„í„°ë“¤
            if product_type:
                english_product_type = translate_to_english(product_type)
                product_type_terms = [product_type, english_product_type] if english_product_type != product_type else [product_type]
                product_type_conditions = []
                for term in product_type_terms:
                    product_type_conditions.append("LOWER(product_type) LIKE LOWER(?)")
                    additional_params.append(f"%{term}%")
                additional_conditions.append(f"({' OR '.join(product_type_conditions)})")
                
            if company:
                english_company = translate_to_english(company)
                company_terms = [company, english_company] if english_company != company else [company]
                company_conditions = []
                for term in company_terms:
                    company_conditions.append("LOWER(company_name) LIKE LOWER(?)")
                    additional_params.append(f"%{term}%")
                additional_conditions.append(f"({' OR '.join(company_conditions)})")
                
            if brand:
                english_brand = translate_to_english(brand)
                brand_terms = [brand, english_brand] if english_brand != brand else [brand]
                brand_conditions = []
                for term in brand_terms:
                    brand_conditions.append("LOWER(brand_name) LIKE LOWER(?)")
                    additional_params.append(f"%{term}%")
                additional_conditions.append(f"({' OR '.join(brand_conditions)})")
            
            # ìµœì¢… WHERE ì ˆ
            final_where = base_where
            final_params = base_params.copy()
            
            if additional_conditions:
                final_where += " AND " + " AND ".join(additional_conditions)
                final_params.extend(additional_params)
            
            # ë©”íŠ¸ë¦­ë³„ ì¿¼ë¦¬ ì‹¤í–‰
            if metric == "count":
                sql = f"SELECT COUNT(*) as value FROM recalls {final_where}"
            elif metric == "companies":
                sql = f"SELECT COUNT(DISTINCT company_name) as value FROM recalls {final_where} AND company_name IS NOT NULL AND company_name != ''"
            elif metric == "brands":  # ë¸Œëœë“œ ìˆ˜ ë©”íŠ¸ë¦­
                sql = f"SELECT COUNT(DISTINCT brand_name) as value FROM recalls {final_where} AND brand_name IS NOT NULL AND brand_name != ''"
            elif metric == "product_types":  # ì œí’ˆ ìœ í˜• ìˆ˜ ë©”íŠ¸ë¦­  
                sql = f"SELECT COUNT(DISTINCT product_type) as value FROM recalls {final_where} AND product_type IS NOT NULL AND product_type != ''"
            else:
                sql = f"SELECT COUNT(*) as value FROM recalls {final_where}"
            
            cursor.execute(sql, final_params)
            result = cursor.fetchone()
            result_data["total"] = result["value"] if result else 0
            
            # ë¦¬ì½œ ì‚¬ìœ ë³„ ë¶„ì„ (í˜„ì¬ JSON êµ¬ì¡°)
            if include_reasons or "ì›ì¸" in str(period) or "ì‚¬ìœ " in str(period):
                reason_sql = f"""
                    SELECT recall_reason, COUNT(*) as count 
                    FROM recalls 
                    {final_where} AND recall_reason IS NOT NULL AND recall_reason != ''
                    GROUP BY recall_reason 
                    ORDER BY count DESC 
                    LIMIT 5
                """
                cursor.execute(reason_sql, final_params)
                reasons = [{"reason": row["recall_reason"], "count": row["count"]} for row in cursor.fetchall()]
                result_data["top_reasons"] = reasons
            
            # ìƒì„¸ ì‚¬ìœ ë³„ ë¶„ì„ (ì˜¤ì—¼ë¬¼ì§ˆ, ì•Œë ˆë¥´ê² ë“±)
            if include_reasons:
                detail_sql = f"""
                    SELECT recall_reason_detail, COUNT(*) as count 
                    FROM recalls 
                    {final_where} AND recall_reason_detail IS NOT NULL AND recall_reason_detail != ''
                    GROUP BY recall_reason_detail 
                    ORDER BY count DESC 
                    LIMIT 5
                """
                cursor.execute(detail_sql, final_params)
                details = [{"detail": row["recall_reason_detail"], "count": row["count"]} for row in cursor.fetchall()]
                result_data["top_details"] = details
            
            return result_data
        
        # ê° ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
        data1 = get_period_data(actual_period1)
        data2 = get_period_data(actual_period2)
        
        if data1 is None or data2 is None:
            return {"error": "ì˜ëª»ëœ ê¸°ê°„ í˜•ì‹ì…ë‹ˆë‹¤. YYYY ë˜ëŠ” YYYY-MM í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”."}
        
        # ë³€í™”ìœ¨ ê³„ì‚° ë° ë¶„ì„
        value1 = data1.get("total", 0)  # 2024ë…„: 240
        value2 = data2.get("total", 0)  # 2025ë…„: 125
        change = value2 - value1        # 125 - 240 = -115
        change_percent = (change / value1 * 100) if value1 > 0 else 0

        if change_percent > 10:
            trend = "significant_increase"
            trend_description = "í¬ê²Œ ì¦ê°€"
        elif change_percent > 3:
            trend = "moderate_increase"  
            trend_description = "ì•½ê°„ ì¦ê°€"
        elif change_percent < -10:
            trend = "significant_decrease"
            trend_description = "í¬ê²Œ ê°ì†Œ"
        elif change_percent < -3:
            trend = "moderate_decrease"
            trend_description = "ì•½ê°„ ê°ì†Œ"
        else:
            trend = "stable"
            trend_description = "ë¹„ìŠ·í•œ ìˆ˜ì¤€"

        # ğŸ”§ ë””ë²„ê¹…ì„ ìœ„í•´ print
        print(f"ğŸ” value1 (2024): {value1}")
        print(f"ğŸ” value2 (2025): {value2}")  
        print(f"ğŸ” change: {change}")
        print(f"ğŸ” change_percent: {change_percent}")

        return {
            "period1": {"period": f"{period1}({actual_period1})", "data": data1},
            "period2": {"period": f"{period2}({actual_period2})", "data": data2},
            "comparison": {
                "change": change,
                "change_percent": round(change_percent, 1),  # ğŸ”§ ì†Œìˆ˜ì  ë°˜ì˜¬ë¦¼ í™•ì¸
                "trend": trend,
                "trend_description": trend_description
            },
            "filters": {
                "metric": metric,
                "product_type": product_type,
                "company": company,
                "brand": brand,
                "keyword": keyword,
                "date_field": date_column
            },
            "query_type": "enhanced_period_comparison",
            "actual_periods": [actual_period1, actual_period2]
        }
        
    except Exception as e:
        return {"error": f"ê¸°ê°„ ë¹„êµ ì˜¤ë¥˜: {e}"}
    

@tool
def search_recall_cases(query: str, limit: int = 5) -> Dict[str, Any]:
    """ChromaDB ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰ (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤ + í•œì˜ ë²ˆì—­ ì§€ì›)"""
    
    _, vectorstore, _ = _get_system_components()
    
    if not vectorstore:
        return {"error": "ChromaDB ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # í–¥ìƒëœ ê²€ìƒ‰ì–´ í™•ì¥ ì „ëµ
        search_queries = []
        search_queries.append(query)  # ì›ë³¸ ì§ˆë¬¸
        
        # í•µì‹¬ í‚¤ì›Œë“œ ë§¤í•‘ (í˜„ì¬ ë°ì´í„°ì— ë§ì¶¤)
        enhanced_translations = {
            # ì˜¤ì—¼ë¬¼ì§ˆ/ì„¸ê· 
            "ì‚´ëª¨ë„¬ë¼": ["Salmonella", "salmonella contamination"],
            "ë¦¬ìŠ¤í…Œë¦¬ì•„": ["Listeria", "Listeria monocytogenes"],
            "ëŒ€ì¥ê· ": ["E.coli", "E. coli", "Escherichia coli"],
            "í´ë¡œìŠ¤íŠ¸ë¦¬ë“": ["Clostridium", "clostridium botulinum"],
            
            # ì•Œë ˆë¥´ê²
            "ìš°ìœ ": ["milk", "dairy", "undeclared milk"],
            "ê³„ë€": ["egg", "eggs", "undeclared egg"],
            "ê²¬ê³¼ë¥˜": ["tree nuts", "nuts", "undeclared nuts"],
            "ë•…ì½©": ["peanut", "peanuts", "undeclared peanut"],
            "ì½©": ["soy", "soybean", "undeclared soy"],
            "ë°€": ["wheat", "gluten", "undeclared wheat"],
            
            # ì œí’ˆ ì¹´í…Œê³ ë¦¬
            "ë³µí•© ê°€ê³µì‹í’ˆ": ["processed foods", "processed products"],
            "ì†ŒìŠ¤ ë³µí•©ì‹í’ˆ": ["sauce processed food", "sauce products"],
            "ê³¼ì": ["snacks", "crackers", "cookies"],
            "ìœ ì œí’ˆ": ["dairy products", "milk products"],
            "í•´ì‚°ë¬¼": ["seafood", "fish products"],
            "ìœ¡ë¥˜": ["meat products", "meat"],
            
            # ì¼ë°˜ ìš©ì–´
            "ì•Œë ˆë¥´ê²": ["allergen", "undeclared allergen"],
            "ì˜¤ì—¼": ["contamination", "contaminated"],
            "ë¦¬ì½œ": ["recall", "voluntary recall"],
            "ì‚¬ë¡€": ["cases", "incidents"]
        }
        
        # í‚¤ì›Œë“œë³„ ë²ˆì—­ ë° í™•ì¥
        for ko_term, en_terms in enhanced_translations.items():
            if ko_term in query:
                search_queries.extend(en_terms)
        
        # ì „ì²´ ì¿¼ë¦¬ ë²ˆì—­
        english_query = translate_to_english(query)
        if english_query != query and english_query not in search_queries:
            search_queries.append(english_query)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ ë¬¸ìì—´ í•„í„°ë§
        search_queries = list(dict.fromkeys([q.strip() for q in search_queries if q.strip()]))
        
        print(f"ğŸ” í™•ì¥ëœ ê²€ìƒ‰ì–´: {search_queries}")
        
        all_docs = []
        seen_urls = set()
        
        # ê° ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰ ì‹¤í–‰ (ê°€ì¤‘ì¹˜ ì ìš©)
        for i, search_query in enumerate(search_queries):
            try:
                # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ê²€ìƒ‰ì–´ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì¡°ì •
                search_limit = limit * 3 if i == 0 else limit * 2  # ì›ë³¸ ì¿¼ë¦¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
                
                docs = vectorstore.similarity_search(
                    search_query, 
                    k=search_limit,
                    filter={"document_type": "recall"}  # ë¦¬ì½œ ë¬¸ì„œë§Œ ê²€ìƒ‰
                )
                
                for doc in docs:
                    url = doc.metadata.get("url", "")
                    if url and url not in seen_urls:
                        all_docs.append(doc)
                        seen_urls.add(url)
                        
            except Exception as search_error:
                print(f"ê²€ìƒ‰ì–´ '{search_query}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {search_error}")
                continue
        
        # ê´€ë ¨ì„± ê¸°ë°˜ ì •ë ¬ (ì›ë³¸ ì¿¼ë¦¬ì™€ì˜ ìœ ì‚¬ë„ ìš°ì„ )
        if all_docs:
            # ìƒìœ„ ê²°ê³¼ ì„ íƒ
            selected_docs = all_docs[:limit]
        else:
            selected_docs = []
        
        # ê²°ê³¼ í¬ë§·íŒ… (í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤)
        cases = []
        for doc in selected_docs:
            # í˜„ì¬ ChromaDB ë©”íƒ€ë°ì´í„° êµ¬ì¡°ì— ë§ì¶¤
            case_data = {
                "company": doc.metadata.get("company_name", "ì •ë³´ ì—†ìŒ"),
                "brand": doc.metadata.get("brand_name", "ì •ë³´ ì—†ìŒ"),
                "product_type": doc.metadata.get("product_type", "ì •ë³´ ì—†ìŒ"),
                "recall_reason": doc.metadata.get("recall_reason", "ì •ë³´ ì—†ìŒ"),
                "recall_detail": doc.metadata.get("recall_reason_detail", "ì •ë³´ ì—†ìŒ"),
                "fda_date": doc.metadata.get("fda_publish_date", "ì •ë³´ ì—†ìŒ"),
                "company_date": doc.metadata.get("company_announcement_date", "ì •ë³´ ì—†ìŒ"),
                "url": doc.metadata.get("url", ""),
                "content_preview": doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content,
                "chunk_info": {
                    "chunk_index": doc.metadata.get("chunk_index", 0),
                    "total_chunks": doc.metadata.get("total_chunks", 1),
                    "is_chunked": doc.metadata.get("is_chunked", False)
                }
            }
            
            cases.append(case_data)
        
        # ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€
        search_quality = evaluate_search_quality(query, cases)
        
        return {
            "cases": cases,
            "total_found": len(cases),
            "original_query": query,
            "search_queries": search_queries,
            "search_method": "enhanced_multilingual_search",
            "search_quality": search_quality,
            "data_structure": "current_json_format"
        }
        
    except Exception as e:
        return {"error": f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}

def evaluate_search_quality(query: str, cases: list) -> Dict[str, Any]:
    """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€"""
    
    if not cases:
        return {"score": 0, "assessment": "no_results"}
    
    try:
        query_lower = query.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        keyword_matches = 0
        total_cases = len(cases)
        
        search_keywords = [
            "ì‚´ëª¨ë„¬ë¼", "salmonella", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "listeria", 
            "ëŒ€ì¥ê· ", "e.coli", "ì•Œë ˆë¥´ê²", "allergen",
            "ìš°ìœ ", "milk", "ê³„ë€", "egg", "ê²¬ê³¼ë¥˜", "nuts"]
        
        for case in cases:
            case_text = " ".join([
                str(case.get("recall_reason", "")),
                str(case.get("recall_detail", "")),
                str(case.get("content_preview", ""))
            ]).lower()
            
            for keyword in search_keywords:
                if keyword in query_lower and keyword in case_text:
                    keyword_matches += 1
                    break
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)
        match_ratio = keyword_matches / total_cases if total_cases > 0 else 0
        quality_score = min(100, int(match_ratio * 100 + (total_cases * 10)))
        
        # í‰ê°€ ë“±ê¸‰
        if quality_score >= 80:
            assessment = "excellent"
        elif quality_score >= 60:
            assessment = "good"
        elif quality_score >= 40:
            assessment = "fair"
        else:
            assessment = "poor"
        
        return {
            "score": quality_score,
            "assessment": assessment,
            "keyword_matches": keyword_matches,
            "total_results": total_cases,
            "match_ratio": round(match_ratio, 2)
        }
        
    except Exception as e:
        return {"score": 0, "assessment": "evaluation_error", "error": str(e)}
    


@tool
def filter_exclude_conditions(exclude_terms: List[str],
                             include_terms: Optional[List[str]] = None,
                             limit: int = 10) -> Dict[str, Any]:
    """íŠ¹ì • ì¡°ê±´ì„ ì œì™¸í•œ ë°ì´í„° í•„í„°ë§ (SQLite ê¸°ë°˜, í˜„ì¬ JSON êµ¬ì¡° ë§ì¶¤)
    
    Args:
        exclude_terms: ì œì™¸í•  ì¡°ê±´ë“¤ (ì˜ˆ: ["ì‚´ëª¨ë„¬ë¼", "ìš°ìœ "])
        include_terms: í¬í•¨í•  ì¡°ê±´ë“¤ (ì„ íƒì‚¬í•­, ì˜ˆ: ["ì•Œë ˆë¥´ê²", "ì„¸ê· "])
        limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        cursor = sqlite_conn.cursor()
        
        # ê¸°ë³¸ ì¿¼ë¦¬ êµ¬ì„± (ëª¨ë“  ì£¼ìš” í•„ë“œ í¬í•¨)
        sql = """
            SELECT company_name, brand_name, product_type, recall_reason, 
                   recall_reason_detail, fda_publish_date, url
            FROM recalls 
            WHERE 1=1
        """
        params = []
        
        # í¬í•¨ ì¡°ê±´ ì²˜ë¦¬ (OR ì¡°ê±´)
        if include_terms:
            include_conditions = []
            for term in include_terms:
                english_term = translate_to_english(term)
                search_terms = [term, english_term] if english_term != term else [term]
                
                for search_term in search_terms:
                    include_conditions.append("""(
                        LOWER(company_name) LIKE LOWER(?) OR
                        LOWER(brand_name) LIKE LOWER(?) OR
                        LOWER(product_type) LIKE LOWER(?) OR
                        LOWER(recall_reason) LIKE LOWER(?) OR
                        LOWER(recall_reason_detail) LIKE LOWER(?) OR
                        LOWER(content) LIKE LOWER(?)
                    )""")
                    params.extend([f"%{search_term}%"] * 6)
            
            sql += f" AND ({' OR '.join(include_conditions)})"
        
        # ì œì™¸ ì¡°ê±´ ì²˜ë¦¬ (AND NOT ì¡°ê±´)
        if exclude_terms:
            exclude_conditions = []
            for term in exclude_terms:
                english_term = translate_to_english(term)
                search_terms = [term, english_term] if english_term != term else [term]
                
                term_conditions = []
                for search_term in search_terms:
                    term_conditions.append("""(
                        LOWER(company_name) LIKE LOWER(?) OR
                        LOWER(brand_name) LIKE LOWER(?) OR
                        LOWER(product_type) LIKE LOWER(?) OR
                        LOWER(recall_reason) LIKE LOWER(?) OR
                        LOWER(recall_reason_detail) LIKE LOWER(?) OR
                        LOWER(content) LIKE LOWER(?)
                    )""")
                    params.extend([f"%{search_term}%"] * 6)
                
                exclude_conditions.append(f"({' OR '.join(term_conditions)})")
            
            sql += f" AND NOT ({' OR '.join(exclude_conditions)})"
        
        sql += " ORDER BY fda_publish_date DESC LIMIT ?"
        params.append(limit)
        
        print(f"ğŸ”§ ì œì™¸ í•„í„°ë§ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„° ìˆ˜: {len(params)}")
        
        # ë©”ì¸ ì¿¼ë¦¬ ì‹¤í–‰
        cursor.execute(sql, params)
        filtered_results = cursor.fetchall()
        
        # í†µê³„ ê³„ì‚°ì„ ìœ„í•œ ë³„ë„ ì¿¼ë¦¬ë“¤
        stats = calculate_filter_statistics(cursor, include_terms, exclude_terms)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        cases = []
        for row in filtered_results:
            cases.append({
                "company": row["company_name"] or "ì •ë³´ ì—†ìŒ",
                "brand": row["brand_name"] or "ì •ë³´ ì—†ìŒ", 
                "product_type": row["product_type"] or "ì •ë³´ ì—†ìŒ",
                "recall_reason": row["recall_reason"] or "ì •ë³´ ì—†ìŒ",
                "recall_detail": row["recall_reason_detail"] or "ì •ë³´ ì—†ìŒ",
                "fda_date": row["fda_publish_date"] or "ì •ë³´ ì—†ìŒ",
                "url": row["url"] or ""
            })
        
        return {
            "filtered_cases": cases,
            "total_found": len(cases),
            "statistics": stats,
            "filters": {
                "include_terms": include_terms or [],
                "exclude_terms": exclude_terms,
                "limit": limit
            },
            "query_type": "exclude_filter"
        }
        
    except Exception as e:
        return {"error": f"ì œì™¸ í•„í„°ë§ ì˜¤ë¥˜: {e}"}
    
#-----------------------
# ë©”ì¸ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
#-----------------------
    

class FunctionCallRecallSystem:
    """Function Calling ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ì½œ ì‹œìŠ¤í…œ - ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í†µí•©"""
    
    def __init__(self):
        self.tools = [
            count_recalls, rank_by_field, get_monthly_trend, 
            compare_periods, search_recall_cases, filter_exclude_conditions
        ]
        # OpenAI Function Calling ëª¨ë¸
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0
        ).bind_tools(self.tools)
        
        # ë‹µë³€ ìƒì„±ìš© LLM (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©)
        self.answer_llm = ChatOpenAI(
            model="gpt-4o-mini", 
            temperature=0.3
        )

        self.cache = {}   #--ì¶”ê°€

    ###ì¶”ê°€#####
    def _get_cache_key(self, question: str) -> str:
        """ì§ˆë¬¸ì„ ìºì‹œ í‚¤ë¡œ ë³€í™˜"""
        import re
        normalized = re.sub(r'[^\w\s]', '', question.lower().strip())
        return re.sub(r'\s+', '_', normalized)
    
    def process_question(self, question: str, chat_history: List = None) -> Dict[str, Any]:
        """Function Callingìœ¼ë¡œ ì§ˆë¬¸ ì²˜ë¦¬ - ê¸°ì¡´ê³¼ ë™ì¼"""
        
        ###ì¶”ê°€####
        cache_key = self._get_cache_key(question)
        if cache_key in self.cache:
            print(f"ğŸ’¨ ìºì‹œ ì‚¬ìš©: {question[:30]}...")
            return self.cache[cache_key]

        if chat_history is None:
            chat_history = []
        
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = """
                ë‹¹ì‹ ì€ FDA ë¦¬ì½œ ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

                ğŸ—“ï¸ í˜„ì¬ ì‹œì  ì •ë³´:
                - í˜„ì¬ ì—°ë„: 2025ë…„
                - ì‘ë…„: 2024ë…„  
                - ì¬ì‘ë…„: 2023ë…„

                âš ï¸ **ë‚ ì§œ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì ˆëŒ€ ê·œì¹™**:
                - ì‚¬ìš©ìê°€ "ì‘ë…„"ì´ë¼ê³  í•˜ë©´ â†’ period1="ì‘ë…„" ë˜ëŠ” period2="ì‘ë…„"ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                - ì‚¬ìš©ìê°€ "ì˜¬í•´"ë¼ê³  í•˜ë©´ â†’ period1="ì˜¬í•´" ë˜ëŠ” period2="ì˜¬í•´"ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬  
                - ì ˆëŒ€ë¡œ "ì‘ë…„"ì„ "2024"ë¡œ ë°”ê¾¸ê±°ë‚˜ "ì˜¬í•´"ë¥¼ "2025"ë¡œ ë°”ê¾¸ì§€ ë§ê³  ì›ë³¸ ê·¸ëŒ€ë¡œ ì „ë‹¬

                ğŸ¯ í•¨ìˆ˜ ì„ íƒ ê°€ì´ë“œë¼ì¸:

                1. **ìˆ˜ì¹˜/í†µê³„ ì§ˆë¬¸** (SQLite ê¸°ë°˜):
                - "ì´ ê±´ìˆ˜", "ëª‡ ê±´" â†’ count_recalls()
                - "ìƒìœ„ Nê°œ", "ìˆœìœ„", "ê°€ì¥ ë§ì€" â†’ rank_by_field()  
                - "ì›”ë³„ íŠ¸ë Œë“œ", "ì¦ê°€/ê°ì†Œ" â†’ get_monthly_trend()
                - "ì‘ë…„ê³¼ ì˜¬í•´", "2023ë…„ vs 2024ë…„" â†’ compare_periods()

                2. **ì‚¬ë¡€ ê²€ìƒ‰** (ChromaDB ê¸°ë°˜):
                - "ì‚¬ë¡€ ì•Œë ¤ì¤˜", "ì–´ë–¤ ì œí’ˆ", "êµ¬ì²´ì ì¸ ë‚´ìš©" â†’ search_recall_cases()

                3. **ì œì™¸ ì¡°ê±´ í•„í„°ë§**:
                - "Aì—ì„œ Bë¥¼ ì œì™¸í•œ", "A ë¹¼ê³ " â†’ filter_exclude_conditions()

                ğŸ”§ í•µì‹¬ ë§¤í•‘ ê·œì¹™:

                **í•„ë“œ ë§¤í•‘ (í˜„ì¬ JSON êµ¬ì¡°)**:
                - íšŒì‚¬/ê¸°ì—… â†’ company_name
                - ë¸Œëœë“œ/ìƒí‘œ â†’ brand_name  
                - ì œí’ˆ/ì‹í’ˆ â†’ product_type
                - ë¦¬ì½œì‚¬ìœ /ì›ì¸ â†’ recall_reason
                - ìƒì„¸ì‚¬ìœ  â†’ recall_reason_detail

                **í‚¤ì›Œë“œ í†µí•© ê²€ìƒ‰**:
                - "ê³„ë€", "ìš°ìœ ", "ê²¬ê³¼ë¥˜" ë“± ì‹í’ˆ ì¹´í…Œê³ ë¦¬ â†’ keyword íŒŒë¼ë¯¸í„° ì‚¬ìš©
                - keywordëŠ” ëª¨ë“  í•„ë“œ(company_name, brand_name, product_type, recall_reason, recall_reason_detail)ì—ì„œ ìë™ í†µí•© ê²€ìƒ‰

                **ë²ˆì—­ ë§¤í•‘**:
                - "ë³µí•© ê°€ê³µì‹í’ˆ" = "processed foods"
                - "ì‚´ëª¨ë„¬ë¼" = "Salmonella"
                - "ë¦¬ìŠ¤í…Œë¦¬ì•„" = "Listeria"
                - "ì•Œë ˆë¥´ê²" = "allergen"

                ğŸ¯ ì§ˆë¬¸ ìœ í˜•ë³„ í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ:

                **ê±´ìˆ˜ ì§ˆë¬¸**:
                - "ê³„ë€ ê´€ë ¨ ë¦¬ì½œ ì´ ëª‡ ê±´?" â†’ count_recalls(keyword="ê³„ë€")
                - "2024ë…„ ì´ ë¦¬ì½œ ê±´ìˆ˜ëŠ”?" â†’ count_recalls(year="2024")
                - "ëª¬ë¸ë¦¬ì¦ˆ íšŒì‚¬ ë¦¬ì½œ ëª‡ ê±´?" â†’ count_recalls(company="ëª¬ë¸ë¦¬ì¦ˆ")

                **ìˆœìœ„ ì§ˆë¬¸**:
                - "ì£¼ìš” ë¦¬ì½œ ì‚¬ìœ  5ê°€ì§€" â†’ rank_by_field(field="recall_reason", limit=5)
                - "ìƒìœ„ íšŒì‚¬ 10ê³³" â†’ rank_by_field(field="company", limit=10)
                - "ê³¼ìë¥˜ ë¸Œëœë“œ ìˆœìœ„" â†’ rank_by_field(field="brand", product_type="ê³¼ì")

                **íŠ¸ë Œë“œ ì§ˆë¬¸**:
                - "ìµœê·¼ 6ê°œì›” íŠ¸ë Œë“œ" â†’ get_monthly_trend(months=6)
                - "ì•Œë ˆë¥´ê² ì›”ë³„ í˜„í™©" â†’ get_monthly_trend(keyword="ì•Œë ˆë¥´ê²")
                - "ëª¬ë¸ë¦¬ì¦ˆ íŠ¸ë Œë“œ" â†’ get_monthly_trend(company="ëª¬ë¸ë¦¬ì¦ˆ")

                **ë¹„êµ ì§ˆë¬¸**:
                - "ì‘ë…„ê³¼ ì˜¬í•´ ë¦¬ì½œ ë¹„êµ" â†’ compare_periods("ì‘ë…„", "ì˜¬í•´")
                - "2023ë…„ vs 2024ë…„ ì•Œë ˆë¥´ê² ë¹„êµ" â†’ compare_periods("2023", "2024", keyword="ì•Œë ˆë¥´ê²", include_reasons=True)

                **ì‚¬ë¡€ ê²€ìƒ‰**:
                - "ì‚´ëª¨ë„¬ë¼ ê´€ë ¨ ì‚¬ë¡€ ì•Œë ¤ì¤˜" â†’ search_recall_cases("ì‚´ëª¨ë„¬ë¼")
                - "ë³µí•© ê°€ê³µì‹í’ˆ ì‚¬ë¡€" â†’ search_recall_cases("ë³µí•© ê°€ê³µì‹í’ˆ")

                **ì œì™¸ ì¡°ê±´**:
                - "ì•Œë ˆë¥´ê² ê´€ë ¨ì¸ë° ìš°ìœ ëŠ” ì œì™¸" â†’ filter_exclude_conditions(include_terms=["ì•Œë ˆë¥´ê²"], exclude_terms=["ìš°ìœ "])
                - "ì„¸ê·  ì˜¤ì—¼ì—ì„œ ì‚´ëª¨ë„¬ë¼ ë¹¼ê³ " â†’ filter_exclude_conditions(include_terms=["ì„¸ê· "], exclude_terms=["ì‚´ëª¨ë„¬ë¼"])

                âš¡ ì¤‘ìš” ì°¸ê³ ì‚¬í•­:
                - í•œêµ­ì–´ ì§ˆë¬¸ì´ì§€ë§Œ ë°ì´í„°ëŠ” ì˜ì–´ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ
                - ê²€ìƒ‰ ì‹œ í•œì˜ ë²ˆì—­ ìë™ ì§€ì›
                - ìˆ˜ì¹˜ëŠ” SQLite, ë‚´ìš© ê²€ìƒ‰ì€ ChromaDB ì‚¬ìš©
                - íŠ¹ì • ì‹í’ˆ ì¹´í…Œê³ ë¦¬ëŠ” keyword íŒŒë¼ë¯¸í„°ë¡œ í†µí•© ê²€ìƒ‰
                - ë‚ ì§œëŠ” ì›ë³¸ í‘œí˜„ ê·¸ëŒ€ë¡œ ì „ë‹¬ ("ì‘ë…„" â†’ "ì‘ë…„")
                """

            
            # ëŒ€í™” ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_prompt},
                *[{"role": msg.type, "content": msg.content} for msg in chat_history[-6:]],
                {"role": "user", "content": question}
            ]
            
            # Function Calling ì‹¤í–‰
            response = self.llm.invoke(messages)
            
            # í•¨ìˆ˜ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš° ì‹¤í–‰
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"ğŸ”§ Function Calls: {len(response.tool_calls)}ê°œ")
                
                tool_results = []
                for tool_call in response.tool_calls:
                    func_name = tool_call['name']
                    func_args = tool_call.get('args', {})
                    
                    print(f"  â†’ {func_name}({func_args})")
                    
                    # í•¨ìˆ˜ ì‹¤í–‰
                    for tool in self.tools:
                        if tool.name == func_name:
                            result = tool.invoke(func_args)
                            tool_results.append({
                                "function": func_name,
                                "args": func_args,
                                "result": result
                            })
                            break
                
                # ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
                final_answer = self._generate_final_answer(question, tool_results)
                
                # ğŸ¬ ê²°ê³¼ ìƒì„± ë° ìºì‹œ ì €ì¥
                result = {
                    "answer": final_answer,
                    "function_calls": tool_results,
                    "processing_type": "function_calling"
                }
            
            else:
                # ì¼ë°˜ ë‹µë³€
                result = {
                    "answer": response.content,
                    "function_calls": [],
                    "processing_type": "direct_answer"
                }
            
            # ğŸ¬ ìºì‹œì— ì €ì¥
            self.cache[cache_key] = result
            return result

                
        except Exception as e:
            error_result = {
                "answer": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                "function_calls": [],
                "processing_type": "error"
            }
            return error_result 
    
    def _generate_final_answer(self, question: str, tool_results: List[Dict]) -> str:
        """ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•œ ë‹µë³€ ìƒì„±"""
        
        if not tool_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        answer_context = self._build_answer_context(tool_results)
        selected_prompt = self._select_prompt_template(question, tool_results)
        
        try:
            # ì „ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
            final_prompt = selected_prompt.format(
                question=question,
                **answer_context
            )
            
            response = self.answer_llm.invoke([
                {"role": "system", "content": "ë‹¹ì‹ ì€ FDA ë¦¬ì½œ ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": final_prompt}
            ])
            
            return response.content
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            return self._generate_basic_answer(question, tool_results)
    
    def _select_prompt_template(self, question: str, tool_results: List[Dict]) -> str:
        """ì§ˆë¬¸ê³¼ ê²°ê³¼ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ"""
        
        # ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        if any("search_recall_cases" == tr["function"] for tr in tool_results):
            return RecallPrompts.RECALL_ANSWER
        
        # ìˆ˜ì¹˜/í†µê³„ ë¶„ì„ ê²°ê³¼
        elif any(tr["function"] in ["count_recalls", "rank_by_field", "get_monthly_trend"] 
                for tr in tool_results):
            return RecallPrompts.NUMERICAL_ANSWER
        
        # ë…¼ë¦¬ ì—°ì‚°/ë¹„êµ ë¶„ì„ ê²°ê³¼  
        elif any(tr["function"] in ["compare_periods", "filter_exclude_conditions"]
                for tr in tool_results):
            return RecallPrompts.LOGICAL_ANSWER
        
        # ê¸°ë³¸: ë¦¬ì½œ ë‹µë³€ í…œí”Œë¦¿
        else:
            return RecallPrompts.RECALL_ANSWER
    
    def _build_answer_context(self, tool_results: List[Dict]) -> Dict[str, str]:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        
        context = {}
        
        # ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        search_results = [tr for tr in tool_results if tr["function"] == "search_recall_cases"]
        if search_results:
            cases = search_results[0]["result"].get("cases", [])
            context["recall_context"] = self._format_cases_for_prompt(cases)
        
        # ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        numerical_results = [tr for tr in tool_results 
                           if tr["function"] in ["count_recalls", "rank_by_field", "get_monthly_trend"]]
        if numerical_results:
            context.update(self._format_numerical_for_prompt(numerical_results))
        
        # ë…¼ë¦¬ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        logical_results = [tr for tr in tool_results 
                 if tr["function"] in ["compare_periods", "filter_exclude_conditions"]]
        if logical_results:
            context.update(self._format_logical_for_prompt(logical_results))
        
        return context
    
    def _format_cases_for_prompt(self, cases: List[Dict]) -> str:
        """ì‚¬ë¡€ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        
        if not cases:
            return "ê´€ë ¨ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        formatted_cases = []
        
        for i, case in enumerate(cases[:8], 1):  # ìµœëŒ€ 8ê±´
            case_text = f"""ì‚¬ë¡€ {i}:
- íšŒì‚¬: {case.get('company', 'Unknown')}
- ë¸Œëœë“œ: {case.get('brand', 'N/A')}
- ì œí’ˆ: {case.get('product_type', 'N/A')}
- ë¦¬ì½œ ì‚¬ìœ : {case.get('recall_reason', 'N/A')}
- ìƒì„¸ ì‚¬ìœ : {case.get('recall_detail', 'N/A')}
- FDA ë°œí‘œì¼: {case.get('fda_date', 'N/A')}
- ì¶œì²˜: {case.get('url', 'N/A')}"""
            formatted_cases.append(case_text.strip())
        
        return "\n\n".join(formatted_cases)
    
    def _format_numerical_for_prompt(self, numerical_results: List[Dict]) -> Dict[str, str]:
        """ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ë³€í™˜"""
        
        context = {}
        
        for tool_result in numerical_results:
            func_name = tool_result["function"]
            result = tool_result["result"]
            
            if func_name == "count_recalls":
                context["analysis_type"] = "ë¦¬ì½œ ê±´ìˆ˜ í†µê³„"
                context["result"] = f"ì´ {result.get('count', 0):,}ê±´"
                context["description"] = f"í•„í„° ì¡°ê±´: {result.get('filters', {})}"
                
            elif func_name == "rank_by_field":
                context["analysis_type"] = f"{result.get('field', '')}ë³„ ìƒìœ„ ìˆœìœ„"
                ranking = result.get("ranking", [])
                context["result"] = "\n".join([
                    f"{i+1}ìœ„: {item['name']} ({item['count']}ê±´)" 
                    for i, item in enumerate(ranking[:10])
                ])
                context["description"] = f"ì´ {len(ranking)}ê°œ í•­ëª© ë¶„ì„"
                
            elif func_name == "get_monthly_trend":
                context["analysis_type"] = "ì›”ë³„ ë¦¬ì½œ íŠ¸ë Œë“œ"
                trend = result.get("trend", [])
                context["result"] = "\n".join([
                    f"{item['month']}: {item['count']}ê±´" 
                    for item in trend[:12]
                ])
                context["description"] = f"ìµœê·¼ {len(trend)}ê°œì›” ë°ì´í„°"
        
        return context
    
    def _format_logical_for_prompt(self, logical_results: List[Dict]) -> Dict[str, str]:
        """ë…¼ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ë³€í™˜"""
        
        context = {}
        
        for tool_result in logical_results:
            func_name = tool_result["function"]
            result = tool_result["result"]
            
            if func_name == "compare_periods":
                context["operation"] = "ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„"
                
                # ğŸ”§ ìƒì„¸í•œ ì •ë³´ í¬í•¨
                period1 = result.get("period1", {})
                period2 = result.get("period2", {})
                comparison = result.get("comparison", {})
                
                # ğŸ”§ êµ¬ì²´ì ì¸ ë°ì´í„° êµ¬ì„±
                detailed_result = f"""
    ê¸°ê°„ 1: {period1.get('period', '')} - {period1.get('data', {}).get('total', 0)}ê±´
    ê¸°ê°„ 2: {period2.get('period', '')} - {period2.get('data', {}).get('total', 0)}ê±´
    ë³€í™”: {comparison.get('change', 0)}ê±´
    ë³€í™”ìœ¨: {comparison.get('change_percent', 0)}%
    ì¶”ì„¸: {comparison.get('trend_description', '')}
                """.strip()
                
                context["result"] = detailed_result
                context["description"] = f"ë‘ ê¸°ê°„ ê°„ ë¦¬ì½œ ê±´ìˆ˜ ë¹„êµ ë¶„ì„ ì™„ë£Œ"
                
            elif func_name == "filter_exclude_conditions":
                # ê¸°ì¡´ ì½”ë“œ ìœ ì§€
                context["operation"] = "ì œì™¸ ì¡°ê±´ í•„í„°ë§"
                cases = result.get("filtered_cases", [])
                stats = result.get("statistics", {})
                context["result"] = f"í•„í„°ë§ëœ ì‚¬ë¡€ {len(cases)}ê±´"
                context["description"] = f"í¬í•¨: {result.get('filters', {}).get('include_terms', [])}, ì œì™¸: {result.get('filters', {}).get('exclude_terms', [])}"

        context["related_links"] = "FDA ê³µì‹ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ë¶„ì„"
        
        return context
    
    def _generate_basic_answer(self, question: str, tool_results: List[Dict]) -> str:
        """í´ë°±ìš© ê¸°ë³¸ ë‹µë³€ ìƒì„± (URL ë§í¬ í¬í•¨)"""
        
        if not tool_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        answer_parts = []
        answer_parts.append("## ğŸ“Š FDA ë¦¬ì½œ ë°ì´í„° ë¶„ì„ ê²°ê³¼\n")
        all_urls = []  # URL ìˆ˜ì§‘ìš©
        
        for tool_result in tool_results:
            func_name = tool_result["function"]
            result = tool_result["result"]
            
            if "error" in result:
                answer_parts.append(f"âš ï¸ {func_name} ì˜¤ë¥˜: {result['error']}\n")
                continue
            
            # í•¨ìˆ˜ë³„ ê²°ê³¼ í¬ë§·íŒ…
            if func_name == "count_recalls":
                count = result.get("count", 0)
                filters = result.get("filters", {})
                answer_parts.append(f"**ì´ ë¦¬ì½œ ê±´ìˆ˜**: {count:,}ê±´")
                if any(filters.values()):
                    answer_parts.append(f"**í•„í„° ì¡°ê±´**: {filters}")
                    
            elif func_name == "rank_by_field":
                field = result.get("field", "")
                ranking = result.get("ranking", [])
                answer_parts.append(f"**{field} ìˆœìœ„**:")
                for i, item in enumerate(ranking[:10], 1):
                    answer_parts.append(f"{i}. {item['name']}: {item['count']}ê±´")
                    
            elif func_name == "get_monthly_trend":
                trend = result.get("trend", [])
                answer_parts.append("**ì›”ë³„ íŠ¸ë Œë“œ**:")
                for item in trend[:6]:
                    answer_parts.append(f"- {item['month']}: {item['count']}ê±´")
                    
            elif func_name == "compare_periods":
                period1 = result.get("period1", {})
                period2 = result.get("period2", {})
                
                # ğŸ”§ ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ change_percent ì°¾ê¸°
                change_percent = (
                    result.get("comparison", {}).get("change_percent", 0) or
                    result.get("change_percent", 0)
                )
                
                answer_parts.append("**ê¸°ê°„ë³„ ë¹„êµ**:")
                answer_parts.append(f"- {period1.get('period', '')}: {period1.get('data', {}).get('total', 0)}ê±´")
                answer_parts.append(f"- {period2.get('period', '')}: {period2.get('data', {}).get('total', 0)}ê±´")
                answer_parts.append(f"- ë³€í™”ìœ¨: {change_percent:+.1f}%")
                
            elif func_name == "search_recall_cases":
                cases = result.get("cases", [])
                answer_parts.append(f"**ê´€ë ¨ ì‚¬ë¡€ {len(cases)}ê±´**:")
                for i, case in enumerate(cases[:5], 1):
                    answer_parts.append(f"{i}. **{case.get('company', 'Unknown')}** - {case.get('product_type', 'N/A')}")
                    answer_parts.append(f"   ì‚¬ìœ : {case.get('recall_reason', 'N/A')}")
                    answer_parts.append(f"   ìƒì„¸: {case.get('recall_detail', 'N/A')}")
                    answer_parts.append(f"   ë°œí‘œì¼: {case.get('fda_date', 'N/A')}")
                    
                    # ê°œë³„ ì‚¬ë¡€ URL ë§í¬ ì¶”ê°€
                    if case.get('url'):
                        answer_parts.append(f"   ğŸ“‹ [ìƒì„¸ ì •ë³´ ë³´ê¸°]({case.get('url')})")
                        all_urls.append(case.get('url'))
                    
            elif func_name == "filter_exclude_conditions":
                filtered_cases = result.get("filtered_cases", [])
                stats = result.get("statistics", {})
                answer_parts.append(f"**í•„í„°ë§ ê²°ê³¼**: {len(filtered_cases)}ê±´")
                answer_parts.append(f"**í†µê³„**: ì „ì²´ {stats.get('total_records', 0)}ê±´ ì¤‘ {stats.get('final_filtered', 0)}ê±´ ì„ ë³„")
                
                # í•„í„°ë§ëœ ì‚¬ë¡€ë“¤ì— URL í¬í•¨
                if filtered_cases:
                    answer_parts.append("**ì£¼ìš” ì‚¬ë¡€**:")
                    for i, case in enumerate(filtered_cases[:3], 1):
                        answer_parts.append(f"{i}. **{case.get('company', 'Unknown')}** - {case.get('product_type', 'N/A')}")
                        answer_parts.append(f"   ì‚¬ìœ : {case.get('recall_reason', 'N/A')}")
                        
                        # URL ë§í¬ ì¶”ê°€
                        if case.get('url'):
                            answer_parts.append(f"   ğŸ“‹ [ìƒì„¸ ì •ë³´ ë³´ê¸°]({case.get('url')})")
                            all_urls.append(case.get('url'))
            
            answer_parts.append("")  # ì„¹ì…˜ êµ¬ë¶„
        
        # ì¶œì²˜ ì„¹ì…˜ ì¶”ê°€
        if all_urls:
            # ì¤‘ë³µ ì œê±°
            unique_urls = list(dict.fromkeys(all_urls))
            answer_parts.append("---")
            answer_parts.append("**ğŸ“š ê´€ë ¨ ì¶œì²˜**:")
            for i, url in enumerate(unique_urls[:5], 1):  # ìµœëŒ€ 5ê°œ
                answer_parts.append(f"{i}. [FDA ê³µì‹ ë¦¬ì½œ ê³µì§€ #{i}]({url})")
            answer_parts.append("")
        
        # ì¼ë°˜ FDA ì¶œì²˜ ë§í¬ í•­ìƒ í¬í•¨
        answer_parts.append("**ğŸ”— ì¶”ê°€ ì •ë³´**:")
        answer_parts.append("- [FDA ë¦¬ì½œ ë° ì•ˆì „ ê²½ê³  ì „ì²´ ëª©ë¡](https://www.fda.gov/safety/recalls-market-withdrawals-safety-alerts/)")
        answer_parts.append("- [FDA ì‹í’ˆ ì•ˆì „ ì •ë³´](https://www.fda.gov/food/food-safety-during-emergencies)")
        
        return "\n".join(answer_parts)
    
# ======================
# ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜ë“¤
# ======================

def create_function_calling_system():
    """Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        return FunctionCallRecallSystem()
    except Exception as e:
        print(f"Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def ask_recall_question_fc(question: str, chat_history: List = None) -> Dict[str, Any]:
    """Function Calling ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬"""
    system = create_function_calling_system()
    if system:
        return system.process_question(question, chat_history)
    else:
        return {
            "answer": "ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            "function_calls": [],
            "processing_type": "error"
        }

def ask_recall_question(question: str, chat_history: List = None) -> Dict[str, Any]:
    """í†µí•©ëœ ë¦¬ì½œ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ (tab_recall.py í˜¸í™˜ìš©)"""
    
    if chat_history is None:
        chat_history = []
    
    try:
        # Function Calling ì‹œìŠ¤í…œ ì‚¬ìš©
        result = ask_recall_question_fc(question, chat_history)
        
        # ê¸°ì¡´ UI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "answer": result["answer"],
            "recall_documents": [],
            "chat_history": chat_history + [
                HumanMessage(content=question),
                AIMessage(content=result["answer"])
            ],
            "processing_type": result["processing_type"],
            "function_calls": result.get("function_calls", []),
            "has_realtime_data": True,
            "realtime_count": len(result.get("function_calls", []))
        }
        
    except Exception as e:
        return {
            "answer": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "recall_documents": [],
            "chat_history": chat_history,
            "processing_type": "error",
            "function_calls": []
        }
    

# === Agent ì—°ë™ìš© íˆ´/ë¦¬ì†ŒìŠ¤ export ===

def export_recall_tools():
    """RecallAgentê°€ ê·¸ëŒ€ë¡œ ë°”ì¸ë”©í•´ì„œ ì“¸ ìˆ˜ ìˆëŠ” LangChain Tool ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        count_recalls,
        rank_by_field,
        get_monthly_trend,
        compare_periods,
        search_recall_cases,
        filter_exclude_conditions,
    ]

def get_sqlite_conn():
    """Agent ë“± ì™¸ë¶€ì—ì„œ ë™ì¼ ì»¤ë„¥ì…˜ì„ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë°˜í™˜"""
    conn, _, _ = _get_system_components()
    return conn

def tool_router(func_name: str, func_args: dict):
    """ì—ì´ì „íŠ¸ê°€ func_nameìœ¼ë¡œ ë°”ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ë¼ìš°í„° (ì„ íƒ)"""
    try:
        tools = {t.name: t for t in export_recall_tools()}
        if func_name in tools:
            return tools[func_name].invoke(func_args or {})
        return {"error": f"Unknown function: {func_name}"}
    except Exception as e:
        return {"error": f"tool_router error: {e}"}